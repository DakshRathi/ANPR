{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytesseract as pt\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as xet\n",
    "from pathlib import Path\n",
    "\n",
    "from glob import glob\n",
    "from skimage import io\n",
    "from shutil import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in datasets directory: [PosixPath('/Users/daksh/Desktop/ANPR/datasets/google_images'), PosixPath('/Users/daksh/Desktop/ANPR/datasets/State-wise_OLX'), PosixPath('/Users/daksh/Desktop/ANPR/datasets/video_images')]\n",
      "Google Images XML files: 440\n",
      "State-wise OLX XML files: 603\n",
      "Video Images XML files: 654\n",
      "Label counts:\n",
      "Google Images: 440\n",
      "State-wise OLX: 603\n",
      "Video Images: 654\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as xet\n",
    "\n",
    "# Define the absolute path to the datasets directory\n",
    "datasets_dir = Path('/Users/daksh/Desktop/ANPR/datasets')\n",
    "\n",
    "# Check if the datasets directory exists\n",
    "if not datasets_dir.exists():\n",
    "    print(\"Datasets directory does not exist.\")\n",
    "else:\n",
    "    # Print the contents of the datasets directory\n",
    "    print(\"Files in datasets directory:\", list(datasets_dir.glob('*')))\n",
    "\n",
    "    # Prepare a function to extract labels from XML files\n",
    "    def extract_labels(xml_paths):\n",
    "        labels_dict = dict(filepath=[], xmin=[], xmax=[], ymin=[], ymax=[])\n",
    "\n",
    "        for filename in xml_paths:\n",
    "            info = xet.parse(filename)\n",
    "            root = info.getroot()\n",
    "            member_object = root.find('object')\n",
    "            labels_info = member_object.find('bndbox')\n",
    "            xmin = int(labels_info.find('xmin').text)\n",
    "            xmax = int(labels_info.find('xmax').text)\n",
    "            ymin = int(labels_info.find('ymin').text)\n",
    "            ymax = int(labels_info.find('ymax').text)\n",
    "\n",
    "            labels_dict['filepath'].append(filename)\n",
    "            labels_dict['xmin'].append(xmin)\n",
    "            labels_dict['xmax'].append(xmax)\n",
    "            labels_dict['ymin'].append(ymin)\n",
    "            labels_dict['ymax'].append(ymax)\n",
    "        \n",
    "        return labels_dict\n",
    "\n",
    "    # Process each subdirectory\n",
    "    google_images_path = datasets_dir / 'google_images'\n",
    "    statewise_olx_path = datasets_dir / 'State-wise_OLX'\n",
    "    video_images_path = datasets_dir / 'video_images'\n",
    "\n",
    "    # Extract labels for google_images\n",
    "    google_images_xml_paths = list(google_images_path.glob('*.xml'))\n",
    "    print(\"Google Images XML files:\", len(google_images_xml_paths))\n",
    "    google_images_labels = extract_labels(google_images_xml_paths)\n",
    "\n",
    "    # Extract labels for State-wise OLX\n",
    "    statewise_olx_xml_paths = list(statewise_olx_path.glob('*/*.xml'))\n",
    "    print(\"State-wise OLX XML files:\", len(statewise_olx_xml_paths))\n",
    "    statewise_olx_labels = extract_labels(statewise_olx_xml_paths)\n",
    "\n",
    "    # Extract labels for video_images\n",
    "    video_images_xml_paths = list(video_images_path.glob('*.xml'))\n",
    "    print(\"Video Images XML files:\", len(video_images_xml_paths))\n",
    "    video_images_labels = extract_labels(video_images_xml_paths)\n",
    "\n",
    "    # Print a summary of the label counts\n",
    "    print(\"Label counts:\")\n",
    "    print(f\"Google Images: {len(google_images_labels['filepath'])}\")\n",
    "    print(f\"State-wise OLX: {len(statewise_olx_labels['filepath'])}\")\n",
    "    print(f\"Video Images: {len(video_images_labels['filepath'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            filepath  xmin  xmax  ymin  ymax  \\\n",
      "0  /Users/daksh/Desktop/ANPR/datasets/google_imag...     1   702    46   401   \n",
      "1  /Users/daksh/Desktop/ANPR/datasets/google_imag...   393   595   452   500   \n",
      "2  /Users/daksh/Desktop/ANPR/datasets/google_imag...   231   431   252   308   \n",
      "3  /Users/daksh/Desktop/ANPR/datasets/google_imag...   606   793   392   469   \n",
      "4  /Users/daksh/Desktop/ANPR/datasets/google_imag...   129   206   131   156   \n",
      "\n",
      "                                            filename  width  height  \n",
      "0  /Users/daksh/Desktop/ANPR/datasets/google_imag...    750     562  \n",
      "1  /Users/daksh/Desktop/ANPR/datasets/google_imag...   1024     685  \n",
      "2  /Users/daksh/Desktop/ANPR/datasets/google_imag...    551     455  \n",
      "3  /Users/daksh/Desktop/ANPR/datasets/google_imag...    930     768  \n",
      "4  /Users/daksh/Desktop/ANPR/datasets/google_imag...    350     196  \n"
     ]
    }
   ],
   "source": [
    "# Function to parse XML files for filename, width, and height\n",
    "def parsing(path: str):\n",
    "    parser = xet.parse(path).getroot()\n",
    "    name = parser.find('filename').text\n",
    "    filename = f'/Users/daksh/Desktop/ANPR/datasets/google_images/{name}'\n",
    "\n",
    "    # width and height\n",
    "    parser_size = parser.find('size')\n",
    "    width = int(parser_size.find('width').text)\n",
    "    height = int(parser_size.find('height').text)\n",
    "    \n",
    "    return filename, width, height\n",
    "\n",
    "def newparsing(path: str):\n",
    "    parser = xet.parse(path).getroot()\n",
    "    name = parser.find('filename').text\n",
    "    filename = f'/Users/daksh/Desktop/ANPR/datasets/State-wise_OLX/{name[:2]}/{name}'\n",
    "\n",
    "    # width and height\n",
    "    parser_size = parser.find('size')\n",
    "    width = int(parser_size.find('width').text)\n",
    "    height = int(parser_size.find('height').text)\n",
    "    \n",
    "    return filename, width, height\n",
    "\n",
    "# Create DataFrames from the dictionaries\n",
    "df_google_images = pd.DataFrame(google_images_labels)\n",
    "df_statewise_olx = pd.DataFrame(statewise_olx_labels)\n",
    "df_video_images = pd.DataFrame(video_images_labels)\n",
    "\n",
    "# Parsing filenames and dimensions for google images\n",
    "df_google_images[['filename', 'width', 'height']] = df_google_images['filepath'].apply(parsing).apply(pd.Series)\n",
    "\n",
    "# Parsing filenames and dimensions for State-wise OLX\n",
    "df_statewise_olx[['filename', 'width', 'height']] = df_statewise_olx['filepath'].apply(newparsing).apply(pd.Series)\n",
    "\n",
    "# Parsing filenames and dimensions for video images\n",
    "def video_parsing(path: str):\n",
    "    parser = xet.parse(path).getroot()\n",
    "    name = parser.find('filename').text\n",
    "    filename = f'/Users/daksh/Desktop/ANPR/datasets/video_images/{name}'\n",
    "\n",
    "    # width and height\n",
    "    parser_size = parser.find('size')\n",
    "    width = int(parser_size.find('width').text)\n",
    "    height = int(parser_size.find('height').text)\n",
    "    \n",
    "    return filename, width, height\n",
    "\n",
    "df_video_images[['filename', 'width', 'height']] = df_video_images['filepath'].apply(video_parsing).apply(pd.Series)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "final_df = pd.concat([df_google_images, df_statewise_olx, df_video_images], ignore_index=True)\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>xmin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymin</th>\n",
       "      <th>ymax</th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>center_x</th>\n",
       "      <th>center_y</th>\n",
       "      <th>bb_width</th>\n",
       "      <th>bb_height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/daksh/Desktop/ANPR/datasets/google_imag...</td>\n",
       "      <td>1</td>\n",
       "      <td>702</td>\n",
       "      <td>46</td>\n",
       "      <td>401</td>\n",
       "      <td>/Users/daksh/Desktop/ANPR/datasets/google_imag...</td>\n",
       "      <td>750</td>\n",
       "      <td>562</td>\n",
       "      <td>0.468667</td>\n",
       "      <td>0.397687</td>\n",
       "      <td>0.934667</td>\n",
       "      <td>0.631673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/daksh/Desktop/ANPR/datasets/google_imag...</td>\n",
       "      <td>393</td>\n",
       "      <td>595</td>\n",
       "      <td>452</td>\n",
       "      <td>500</td>\n",
       "      <td>/Users/daksh/Desktop/ANPR/datasets/google_imag...</td>\n",
       "      <td>1024</td>\n",
       "      <td>685</td>\n",
       "      <td>0.482422</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.197266</td>\n",
       "      <td>0.070073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/daksh/Desktop/ANPR/datasets/google_imag...</td>\n",
       "      <td>231</td>\n",
       "      <td>431</td>\n",
       "      <td>252</td>\n",
       "      <td>308</td>\n",
       "      <td>/Users/daksh/Desktop/ANPR/datasets/google_imag...</td>\n",
       "      <td>551</td>\n",
       "      <td>455</td>\n",
       "      <td>0.600726</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.362976</td>\n",
       "      <td>0.123077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/daksh/Desktop/ANPR/datasets/google_imag...</td>\n",
       "      <td>606</td>\n",
       "      <td>793</td>\n",
       "      <td>392</td>\n",
       "      <td>469</td>\n",
       "      <td>/Users/daksh/Desktop/ANPR/datasets/google_imag...</td>\n",
       "      <td>930</td>\n",
       "      <td>768</td>\n",
       "      <td>0.752151</td>\n",
       "      <td>0.560547</td>\n",
       "      <td>0.201075</td>\n",
       "      <td>0.100260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/daksh/Desktop/ANPR/datasets/google_imag...</td>\n",
       "      <td>129</td>\n",
       "      <td>206</td>\n",
       "      <td>131</td>\n",
       "      <td>156</td>\n",
       "      <td>/Users/daksh/Desktop/ANPR/datasets/google_imag...</td>\n",
       "      <td>350</td>\n",
       "      <td>196</td>\n",
       "      <td>0.478571</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.127551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath  xmin  xmax  ymin  ymax  \\\n",
       "0  /Users/daksh/Desktop/ANPR/datasets/google_imag...     1   702    46   401   \n",
       "1  /Users/daksh/Desktop/ANPR/datasets/google_imag...   393   595   452   500   \n",
       "2  /Users/daksh/Desktop/ANPR/datasets/google_imag...   231   431   252   308   \n",
       "3  /Users/daksh/Desktop/ANPR/datasets/google_imag...   606   793   392   469   \n",
       "4  /Users/daksh/Desktop/ANPR/datasets/google_imag...   129   206   131   156   \n",
       "\n",
       "                                            filename  width  height  center_x  \\\n",
       "0  /Users/daksh/Desktop/ANPR/datasets/google_imag...    750     562  0.468667   \n",
       "1  /Users/daksh/Desktop/ANPR/datasets/google_imag...   1024     685  0.482422   \n",
       "2  /Users/daksh/Desktop/ANPR/datasets/google_imag...    551     455  0.600726   \n",
       "3  /Users/daksh/Desktop/ANPR/datasets/google_imag...    930     768  0.752151   \n",
       "4  /Users/daksh/Desktop/ANPR/datasets/google_imag...    350     196  0.478571   \n",
       "\n",
       "   center_y  bb_width  bb_height  \n",
       "0  0.397687  0.934667   0.631673  \n",
       "1  0.694891  0.197266   0.070073  \n",
       "2  0.615385  0.362976   0.123077  \n",
       "3  0.560547  0.201075   0.100260  \n",
       "4  0.732143  0.220000   0.127551  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# center_x, center_y, width , height\n",
    "df['center_x'] = (df['xmax'] + df['xmin'])/(2*df['width'])\n",
    "df['center_y'] = (df['ymax'] + df['ymin'])/(2*df['height'])\n",
    "\n",
    "df['bb_width'] = (df['xmax'] - df['xmin'])/df['width']\n",
    "df['bb_height'] = (df['ymax'] - df['ymin'])/df['height']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1357\n",
      "Testing set size: 340\n"
     ]
    }
   ],
   "source": [
    "# Assuming df contains the columns needed for splitting\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the number of images in training and testing sets\n",
    "print(f\"Training set size: {len(df_train)}\")\n",
    "print(f\"Testing set size: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing /Users/daksh/Desktop/ANPR/datasets/State-wise_OLX/MH/MH5.jpg: [Errno 2] No such file or directory: '/Users/daksh/Desktop/ANPR/datasets/State-wise_OLX/MH/MH5.jpg'\n",
      "Error processing /Users/daksh/Desktop/ANPR/datasets/State-wise_OLX/NL/NL1.jpg: [Errno 2] No such file or directory: '/Users/daksh/Desktop/ANPR/datasets/State-wise_OLX/NL/NL1.jpg'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from shutil import copy\n",
    "\n",
    "# Define folder paths\n",
    "train_folder = './yolo/data/images/train'\n",
    "test_folder = './yolo/data/images/test'\n",
    "\n",
    "# Ensure the folders exist\n",
    "os.makedirs(train_folder, exist_ok=True)\n",
    "os.makedirs(test_folder, exist_ok=True)\n",
    "os.makedirs('./yolo/data/labels/train', exist_ok=True)\n",
    "os.makedirs('./yolo/data/labels/test', exist_ok=True)\n",
    "\n",
    "# Process training data\n",
    "for _, row in df_train.iterrows():\n",
    "    try:\n",
    "        fname, center_x, center_y, bb_width, bb_height = row[['filename', 'center_x', 'center_y', 'bb_width', 'bb_height']]\n",
    "        image_name = os.path.split(fname)[-1]\n",
    "        txt_name = os.path.splitext(image_name)[0]\n",
    "\n",
    "        dst_image_path = os.path.join(train_folder, image_name)\n",
    "        dst_label_file = os.path.join('./yolo/data/labels/train', txt_name + '.txt')\n",
    "\n",
    "        # Copy each image into the folder\n",
    "        copy(fname, dst_image_path)\n",
    "\n",
    "        # Generate .txt which has label info\n",
    "        label_txt = f'0 {center_x} {center_y} {bb_width} {bb_height}'\n",
    "        with open(dst_label_file, mode='w') as f:\n",
    "            f.write(label_txt)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {fname}: {e}\")\n",
    "\n",
    "# Process testing data\n",
    "for _, row in df_test.iterrows():\n",
    "    try:\n",
    "        fname, center_x, center_y, bb_width, bb_height = row[['filename', 'center_x', 'center_y', 'bb_width', 'bb_height']]\n",
    "        image_name = os.path.split(fname)[-1]\n",
    "        txt_name = os.path.splitext(image_name)[0]\n",
    "\n",
    "        dst_image_path = os.path.join(test_folder, image_name)\n",
    "        dst_label_file = os.path.join('./yolo/data/labels/test', txt_name + '.txt')\n",
    "\n",
    "        # Copy each image into the folder\n",
    "        copy(fname, dst_image_path)\n",
    "\n",
    "        # Generate .txt which has label info\n",
    "        label_txt = f'0 {center_x} {center_y} {bb_width} {bb_height}'\n",
    "        with open(dst_label_file, mode='w') as f:\n",
    "            f.write(label_txt)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {fname}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
